<!doctype html>
<html lang="zh-Hans" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-ai-101/LLMs/develop-LLMs">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.1">
<title data-rh="true">开发大语言模型需要什么？ | Learning Prompt</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://learningpromt.wiki/zh-Hans/docs/ai-101/LLMs/develop-LLMs"><meta data-rh="true" name="docusaurus_locale" content="zh-Hans"><meta data-rh="true" name="docsearch:language" content="zh-Hans"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="开发大语言模型需要什么？ | Learning Prompt"><meta data-rh="true" name="description" content="本文主要内容来自论文 A Survey of Large Language Models。"><meta data-rh="true" property="og:description" content="本文主要内容来自论文 A Survey of Large Language Models。"><link data-rh="true" rel="icon" href="/zh-Hans/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://learningpromt.wiki/zh-Hans/docs/ai-101/LLMs/develop-LLMs"><link data-rh="true" rel="alternate" href="https://learningpromt.wiki/docs/ai-101/LLMs/develop-LLMs" hreflang="en-GB"><link data-rh="true" rel="alternate" href="https://learningpromt.wiki/zh-Hans/docs/ai-101/LLMs/develop-LLMs" hreflang="zh-Hans"><link data-rh="true" rel="alternate" href="https://learningpromt.wiki/docs/ai-101/LLMs/develop-LLMs" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/zh-Hans/blog/rss.xml" title="Learning Prompt RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/zh-Hans/blog/atom.xml" title="Learning Prompt Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-9QBEXE7W09"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-9QBEXE7W09",{anonymize_ip:!0})</script><link rel="stylesheet" href="/zh-Hans/assets/css/styles.f9380350.css">
<link rel="preload" href="/zh-Hans/assets/js/runtime~main.b18096b2.js" as="script">
<link rel="preload" href="/zh-Hans/assets/js/main.69529822.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementBar_mb4j" style="background-color:#fafbfc;color:#091E42" role="banner"><div class="content_knG7 announcementBarContent_xLdY">⭐ If you have any questions, feel free to join our <a target="_blank" href="https://discord.gg/B7Z7wjuUPg">Discord</a>.⭐</div></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/zh-Hans/"><div class="navbar__logo"><img src="/zh-Hans/img/logo.svg" alt="Learning Prompt logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/zh-Hans/img/logo.svg" alt="Learning Prompt logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Learning Prompt</b></a><a class="navbar__item navbar__link" href="/zh-Hans/docs">👋 欢迎</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/zh-Hans/docs/ai-101">🤖 AI 101</a><a class="navbar__item navbar__link" href="/zh-Hans/docs/chatgpt-learning-path">💬 ChatGPT 教程</a><a class="navbar__item navbar__link" href="/zh-Hans/docs/midjourney-learning-path">🖼️ Midjourney 教程</a><a class="navbar__item navbar__link" href="/zh-Hans/blog">📰 更新日志</a></div><div class="navbar__items navbar__items--right"><a href="https://jimmywong.bio/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">😎 关于我<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>简体中文</a><ul class="dropdown__menu"><li><a href="/docs/ai-101/LLMs/develop-LLMs" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="en-GB">English</a></li><li><a href="/zh-Hans/docs/ai-101/LLMs/develop-LLMs" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="zh-Hans">简体中文</a></li></ul></div><a href="https://github.com/thinkingjimmy/Learning-Prompt" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/zh-Hans/docs/ai-101">🤖 AI 101</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/zh-Hans/docs/ai-101/LLMs">📖 语言模型介绍</a><button aria-label="Toggle the collapsible sidebar category &#x27;📖 语言模型介绍&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-Hans/docs/ai-101/LLMs/what-is-LLMs">什么是语言模型？</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-Hans/docs/ai-101/LLMs/how-to-calculate-probability">如何计算概率？</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/zh-Hans/docs/ai-101/LLMs/develop-LLMs">开发大语言模型需要什么？</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/zh-Hans/docs/ai-101/LLMs/LLMs-disadvantages">大语言模型有什么缺点？</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/zh-Hans/docs/ai-101/best-practice">🏗️ AI 最佳实践</a><button aria-label="Toggle the collapsible sidebar category &#x27;🏗️ AI 最佳实践&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/zh-Hans/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/zh-Hans/docs/ai-101/LLMs"><span itemprop="name">📖 语言模型介绍</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">开发大语言模型需要什么？</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>开发大语言模型需要什么？</h1><div class="theme-admonition theme-admonition-info alert alert--info admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_S0QG"><p>本文主要内容来自论文 <a href="https://arxiv.org/abs/2303.18223" target="_blank" rel="noopener noreferrer">A Survey of Large Language Models</a>。</p></div></div><p>了解完大语言模型的原理之后，你可能会好奇 TA 是如何开发的。开发大语言模型的关键是什么。最近看到不少文章为了流量，甚至连 5G 通讯都说成了是开发大语言模型的关键 😂</p><p>其实从前面的原理介绍，不难看出，大语言模型的其中一个关键点是数据。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="关键一数据">关键一：数据<a href="#关键一数据" class="hash-link" aria-label="Direct link to 关键一：数据" title="Direct link to 关键一：数据">​</a></h2><p>训练数据主要是所谓的语料库。今天的很多语言模型的语料库主要有以下几种：</p><ul><li>Books：BookCorpus 是之前小语言模型如 GPT-2 常用的数据集，包括超过 11000 本电子书。主要包括小说和传记，最近更新时间是 2015 年 12 月。大一点的书籍语料库是 Gutenberg，它有 70000 本书，包括小说、散文、戏剧等作品，是目前最大的开源书籍语料库之一，最近更新时间是 2021 年 12 月。</li><li>CommonCrawl：这个是目前最大的开源网络爬虫数据库，不过这个数据包含了大量脏数据，所以目前常用的四个数据库是 C4、CC-Stories、CC-News 和 RealNews。另外还有两个基于 CommonCrawl 提取的新闻语料库 REALNEWS 和 CC-News。</li><li>Reddit Links：简单理解 Reddit 就是外国版本的百度贴吧 + 知乎。目前开源的数据库有 OpenWebText 和 <a href="http://PushShift.io" target="_blank" rel="noopener noreferrer">PushShift.io</a>。</li><li>Wikipedia：维基百科是目前大模型广泛使用的语料库。</li><li>Code：一般包含 GitHub 上的开源公共代码库，或者是 StackOverflow 的数据，Google 之前发布过一个叫 BigQuery 的数据集。</li></ul><p>实际上，训练大语言模型会混合使用不同的数据，一般不会只使用单一语料库。比如 GPT-3 用的混合数据集就包括 Books、CommonCrowl、Reddit Links 和 Wikipedia。</p><p>从数据上看，你需要知道一个事实，中文语料在这上面占比很小。ChatGPT 能用中文回答你的问题，只是因为它的语料里有一些中英文对应的语料，然后模型就像是「懂中文了一样」，所以更可能的情况是，它先生成了英文内容，再翻译成中文。如果你去问 ChatGPT 3.5：请给我几个中文谐音梗，你应该就能理解我说的话了。</p><p>以下是 ChatGPT 的返回结果：</p><div class="language-other codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-other codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">以下是一些中文谐音梗的例子：</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">我蒸发了，意思是我是 Vaper 了（Vaper发音接近蒸发）。</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">会有星期天，都得过过来，意思是星期二，星期三，星期四，星期五，星期六，都得过过来。</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">看到你，我的内心凉了 below zero，意思是凉了半截（below zero与半截音相近）。</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">蜀道难，难于上青天，赛道难，难于上488（488与“蜀道难”同音）。</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">洋葱姑娘，想哭却哭不出来，因为洋葱让我流泪了（洋葱和“要哭”在中文中的发音很相似）。</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">雨纷纷，旧故里草木深，我听闻，你始终在我身边深（“身边深”和“身边寻”谐音）。</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">你的车开得真快，一开就是“出租”，意思是“出祖宗”（发音类似）。</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="关键二算法">关键二：算法<a href="#关键二算法" class="hash-link" aria-label="Direct link to 关键二：算法" title="Direct link to 关键二：算法">​</a></h2><p>有了数据之后，你还需要有算法去做计算，目前最常用的开发大语言模型的算法库有：</p><ol><li>Transformers：这是一个使用 Transformer 架构构建的开源 Python 库。</li><li>DeepSpeed：是由微软开发的深度学习优化库。</li><li>Megatron-LM：这是由 Nvidia 开发的深度学习库。</li><li>JAX：它是由 Google 开发的用于高新能机器学习算法的 Python 库。</li></ol><h2 class="anchor anchorWithStickyNavbar_LWe7" id="关键三算力">关键三：算力<a href="#关键三算力" class="hash-link" aria-label="Direct link to 关键三：算力" title="Direct link to 关键三：算力">​</a></h2><p>简单理解，算力就是计算资源，或者说硬件，OpenAI 没有说它训练 GPT-3 语言模型花了多少计算资源。但 OpenAI 的 CEO 暗示硬件成本超过一亿美元，如果我们按照 1000 美元一个 GPU 计算，它大约使用了 10 万个 GPU，以 32 位运算为准，它能提供超过 100 PFLOPS 的算力，也就是每秒 10 亿亿次运算以上，这大约是阿里云最大的数据中心的四分之一的算力。</p><p>注意，这还是 GPT-3 时的花费。</p><p>另外，我还想分享一个观点，不要以为算力会随时间的前进，就能跨越。算力永远会是制约我们瓶颈，因为我们对人工智能的要求会不断的提高。</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"></div><div class="col lastUpdated_vwxv"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2023-08-24T06:32:29.000Z">2023年8月24日</time></b></span></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/zh-Hans/docs/ai-101/LLMs/how-to-calculate-probability"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">如何计算概率？</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/zh-Hans/docs/ai-101/LLMs/LLMs-disadvantages"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">大语言模型有什么缺点？</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_jeP5 thin-scrollbar theme-doc-toc-desktop"><div class="margin--md"></div><h3 class="padding-left--md padding-top--md margin-bottom--none" style="text-transform:uppercase;font-size:0.75em;color:var(--ifm-color-emphasis-700);letter-spacing:0.5px">Table of Contents</h3><ul class="table-of-contents table-of-contents__left-border"><li><a href="#关键一数据" class="table-of-contents__link toc-highlight">关键一：数据</a></li><li><a href="#关键二算法" class="table-of-contents__link toc-highlight">关键二：算法</a></li><li><a href="#关键三算力" class="table-of-contents__link toc-highlight">关键三：算力</a></li></ul></div></div></div></div></main></div></div></div>
<script src="/zh-Hans/assets/js/runtime~main.b18096b2.js"></script>
<script src="/zh-Hans/assets/js/main.69529822.js"></script>
</body>
</html>